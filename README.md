# Scraper Smartphones Tunisianet

## ğŸ“‹ PrÃ©sentation
Ce projet permet de scraper les informations des smartphones depuis le site [tunisianet.com.tn](https://www.tunisianet.com.tn/596-smartphone-tunisie) et de contrÃ´ler le scraping via une interface web (Streamlit) et un backend Flask.

## ğŸ—‚ï¸ Structure du projet
- `scraper.py` : Script principal de scraping (extraction des donnÃ©es, sauvegarde dans `data.json`).
- `scraper_server.py` : Serveur Flask pour lancer/pauser/reprendre/arrÃªter le scraping Ã  distance (sauvegarde dans `resultats.json`).
- `app.py` : Interface Streamlit pour contrÃ´ler le scraping via le backend Flask.
- `requirements.txt` : DÃ©pendances Python nÃ©cessaires.
- Fichiers de sortie :
  - `data.json` : RÃ©sultat du scraping via `scraper.py` (donnÃ©es dÃ©taillÃ©es).
  - `resultats.json` : RÃ©sultat du scraping via le serveur Flask (titres et URLs).
  - `smartphones.json`, `tayara_ads.json`, etc. : Exemples ou autres jeux de donnÃ©es.

## ğŸš€ Installation
1. **Installer les dÃ©pendances** :
   ```bash
   pip install -r requirements.txt
   ```
2. **Installer Chrome** (si ce n'est pas dÃ©jÃ  fait) et s'assurer que le driver Chrome est compatible (gÃ©rÃ© automatiquement par `webdriver-manager`).

## âš™ï¸ Utilisation
### 1. Scraping direct (manuel)
```bash
python scraper.py
```
- Saisir le nombre de pages Ã  scraper.
- Les rÃ©sultats sont enregistrÃ©s dans `data.json`.

### 2. Scraping via serveur Flask (contrÃ´le Ã  distance)
- Lancer le serveur :
  ```bash
  python scraper_server.py
  ```
- Utiliser les endpoints :
  - `/start` (POST) : DÃ©marrer le scraping
  - `/pause` (POST) : Mettre en pause
  - `/resume` (POST) : Reprendre
  - `/stop` (POST) : ArrÃªter
  - `/status` (GET) : Voir l'Ã©tat
- Les rÃ©sultats sont enregistrÃ©s dans `resultats.json`.

### 3. Interface web (Streamlit)
- Lancer l'interface :
  ```bash
  streamlit run app.py
  ```
- Permet de contrÃ´ler le scraping via le backend Flask (dÃ©marrer, pause, reprise, stop, suivi de la progression).

## ğŸ“¦ Fichiers de sortie
- `data.json` : DonnÃ©es dÃ©taillÃ©es (titre, url, description, rÃ©fÃ©rence, disponibilitÃ©...)
- `resultats.json` : Liste simple (titre, url)
- `smartphones.json` : Exemple de donnÃ©es enrichies (avec prix)
- `tayara_ads.json` : Autres donnÃ©es (exemple d'annonces immobiliÃ¨res)

## ğŸ—ƒï¸ Organisation recommandÃ©e
Pour plus de clartÃ©, il est conseillÃ© de sÃ©parer les scripts dans un dossier dÃ©diÃ© :
```
scraper/
  â”œâ”€â”€ scraper.py
  â””â”€â”€ scraper_server.py
```

---

# ğŸ‡¹ğŸ‡³ Ø´Ø±Ø­ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ØªÙˆÙ†Ø³ÙŠ

Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù‡Ø°Ø§ ÙŠØ¹Ù…Ù„ Ø³ÙƒØ±Ø§ÙŠØ¨ÙŠÙ†Øº (scraping) Ù„Ù„Ø³Ù…Ø§Ø±ØªÙÙˆÙ†Ø§Øª Ù…Ù† Ù…ÙˆÙ‚Ø¹ Tunisianet Ùˆ ÙŠØ¹Ø·ÙŠÙƒ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø§Ø´ ØªØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø³ÙƒØ±Ø§ÙŠØ¨ÙŠÙ†Øº (ØªØ¨Ø¯Ø£ØŒ ØªÙˆÙ‚ÙØŒ ØªÙƒÙ…Ù‘Ù„...).

## ÙƒÙŠÙØ§Ø´ ØªØ®Ø¯Ù… Ø¨ÙŠÙ‡ ØŸ
1. **Ø±ÙƒÙ‘Ø¨ Ø§Ù„Ø¨Ø§ÙƒÙŠØ¬Ø§Øª** :
   ```bash
   pip install -r requirements.txt
   ```
2. **Ø¨Ø§Ø´ ØªØ³ÙƒØ±Ø§Ø¨ÙŠ Ø¨ÙŠØ¯Ùƒ** :
   ```bash
   python scraper.py
   ```
   Ùˆ ØªÙ„Ù‚Ù‰ Ø§Ù„Ø¯Ø§ØªØ§ ÙÙŠ `data.json`
3. **Ø¨Ø§Ø´ ØªØªØ­ÙƒÙ… Ù…Ù† Ø¨Ø¹ÙŠØ¯ (Flask + Streamlit)** :
   - Ø´ØºÙ‘Ù„ Ø§Ù„Ø³ÙŠØ±ÙØ± :
     ```bash
     python scraper_server.py
     ```
   - Ø´ØºÙ‘Ù„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© :
     ```bash
     streamlit run app.py
     ```
   - ØªØ­ÙƒÙ… Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (start, pause, resume, stop)
   - ØªÙ„Ù‚Ù‰ Ø§Ù„Ø¯Ø§ØªØ§ ÙÙŠ `resultats.json`

## Ù…Ù„Ø§Ø­Ø¸Ø©
- ÙŠÙ„Ø²Ù… ÙŠÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ Google Chrome.
- Ø§Ù„Ø³ÙƒØ±Ø§ÙŠØ¨ÙŠÙ†Øº ÙŠØ³ØªØ¹Ù…Ù„ Selenium Ùˆ WebDriver Manager.
- ÙÙ…Ø§ Ø¯Ø§ØªØ§ Ø£Ø®Ø±Ù‰ ÙÙŠ project (ex: smartphones.json, tayara_ads.json) ÙƒØ£Ù…Ø«Ù„Ø©.

---

**Auteur :**
- Projet open-source pour l'apprentissage et l'automatisation du scraping en Tunisie ğŸ‡¹ğŸ‡³ 